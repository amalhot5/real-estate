{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "from tqdm.auto import tqdm\n",
    "from datetime import timedelta\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Calling read(nbytes) on source failed. Try engine='python'.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# get all listing histories\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m lh \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata/crmls_closings_lh_20240607.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m lh[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mupdate_transaction\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(lh[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mupdate_transaction\u001b[39m\u001b[38;5;124m'\u001b[39m], errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoerce\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m lh\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[0;32m~/anaconda3/envs/pw/lib/python3.10/site-packages/pandas/io/parsers/readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    899\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    900\u001b[0m     dialect,\n\u001b[1;32m    901\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    908\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    909\u001b[0m )\n\u001b[1;32m    910\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 912\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pw/lib/python3.10/site-packages/pandas/io/parsers/readers.py:583\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[1;32m    582\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[0;32m--> 583\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pw/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1704\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1697\u001b[0m nrows \u001b[38;5;241m=\u001b[39m validate_integer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnrows\u001b[39m\u001b[38;5;124m\"\u001b[39m, nrows)\n\u001b[1;32m   1698\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1699\u001b[0m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[1;32m   1700\u001b[0m     (\n\u001b[1;32m   1701\u001b[0m         index,\n\u001b[1;32m   1702\u001b[0m         columns,\n\u001b[1;32m   1703\u001b[0m         col_dict,\n\u001b[0;32m-> 1704\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[1;32m   1705\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\n\u001b[1;32m   1706\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1707\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1708\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/anaconda3/envs/pw/lib/python3.10/site-packages/pandas/io/parsers/c_parser_wrapper.py:234\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlow_memory:\n\u001b[0;32m--> 234\u001b[0m         chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_low_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    235\u001b[0m         \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n\u001b[1;32m    236\u001b[0m         data \u001b[38;5;241m=\u001b[39m _concatenate_chunks(chunks)\n",
      "File \u001b[0;32m~/anaconda3/envs/pw/lib/python3.10/site-packages/pandas/_libs/parsers.pyx:814\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/pw/lib/python3.10/site-packages/pandas/_libs/parsers.pyx:875\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/pw/lib/python3.10/site-packages/pandas/_libs/parsers.pyx:850\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/pw/lib/python3.10/site-packages/pandas/_libs/parsers.pyx:861\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/pw/lib/python3.10/site-packages/pandas/_libs/parsers.pyx:2029\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: Calling read(nbytes) on source failed. Try engine='python'."
     ]
    }
   ],
   "source": [
    "# get all listing histories\n",
    "lh = pd.read_csv('data/crmls_closings_lh_20240607.csv')\n",
    "lh['update_transaction'] = pd.to_datetime(lh['update_transaction'], errors='coerce')\n",
    "lh.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14021811\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dpid</th>\n",
       "      <th>recordingdate</th>\n",
       "      <th>salesprice</th>\n",
       "      <th>standardizedlanduse</th>\n",
       "      <th>propertyfullstreetaddress</th>\n",
       "      <th>propertycityname</th>\n",
       "      <th>propertyzipcode</th>\n",
       "      <th>propertyhousenumber</th>\n",
       "      <th>propertyunitnumber</th>\n",
       "      <th>bk_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60010012587</td>\n",
       "      <td>2015-11-04</td>\n",
       "      <td>90000.0</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>229 BRUSH ST</td>\n",
       "      <td>OAKLAND</td>\n",
       "      <td>94607.0</td>\n",
       "      <td>229</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6001001258720151104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60010012587</td>\n",
       "      <td>2016-06-01</td>\n",
       "      <td>205000.0</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>229 BRUSH ST</td>\n",
       "      <td>OAKLAND</td>\n",
       "      <td>94607.0</td>\n",
       "      <td>229</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6001001258720160601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60010012588</td>\n",
       "      <td>2016-06-01</td>\n",
       "      <td>205000.0</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>BRUSH ST</td>\n",
       "      <td>OAKLAND</td>\n",
       "      <td>94607.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6001001258820160601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60010012588</td>\n",
       "      <td>2015-11-04</td>\n",
       "      <td>90000.0</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>BRUSH ST</td>\n",
       "      <td>OAKLAND</td>\n",
       "      <td>94607.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6001001258820151104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60010012590</td>\n",
       "      <td>2004-05-25</td>\n",
       "      <td>410000.0</td>\n",
       "      <td>3010.0</td>\n",
       "      <td>311 OAK ST</td>\n",
       "      <td>OAKLAND</td>\n",
       "      <td>94607.0</td>\n",
       "      <td>311</td>\n",
       "      <td>C1</td>\n",
       "      <td>6001001259020040525</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          dpid recordingdate  salesprice  standardizedlanduse  \\\n",
       "0  60010012587    2015-11-04     90000.0               2012.0   \n",
       "1  60010012587    2016-06-01    205000.0               2012.0   \n",
       "2  60010012588    2016-06-01    205000.0               2012.0   \n",
       "3  60010012588    2015-11-04     90000.0               2012.0   \n",
       "4  60010012590    2004-05-25    410000.0               3010.0   \n",
       "\n",
       "  propertyfullstreetaddress propertycityname  propertyzipcode  \\\n",
       "0              229 BRUSH ST          OAKLAND          94607.0   \n",
       "1              229 BRUSH ST          OAKLAND          94607.0   \n",
       "2                  BRUSH ST          OAKLAND          94607.0   \n",
       "3                  BRUSH ST          OAKLAND          94607.0   \n",
       "4                311 OAK ST          OAKLAND          94607.0   \n",
       "\n",
       "  propertyhousenumber propertyunitnumber                bk_id  \n",
       "0                 229                NaN  6001001258720151104  \n",
       "1                 229                NaN  6001001258720160601  \n",
       "2                 NaN                NaN  6001001258820160601  \n",
       "3                 NaN                NaN  6001001258820151104  \n",
       "4                 311                 C1  6001001259020040525  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bk_deeds = pd.concat([pd.read_csv('data/bk_raw_deeds0.csv'), pd.read_csv('data/bk_raw_deeds1.csv'), pd.read_csv('data/bk_raw_deeds2.csv')])\n",
    "print(len(bk_deeds))\n",
    "bk_deeds['bk_id'] = bk_deeds['dpid'].astype(str) + bk_deeds['recordingdate'].astype(str)\n",
    "bk_deeds['recordingdate'] = pd.to_datetime(bk_deeds['recordingdate'], format='%Y%m%d', errors='coerce')\n",
    "bk_deeds.dropna(subset='recordingdate', inplace=True)\n",
    "bk_deeds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6543940\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0         2024-04-11 04:00:00\n",
       "1         2023-10-16 04:00:00\n",
       "2         2023-08-15 04:00:00\n",
       "3         2023-06-05 04:00:00\n",
       "4         2022-05-19 04:00:00\n",
       "                  ...        \n",
       "1543935   1999-04-15 04:00:00\n",
       "1543936   2010-08-16 04:00:00\n",
       "1543937   2024-06-18 04:00:00\n",
       "1543938   2004-11-19 05:00:00\n",
       "1543939   2024-06-18 04:01:00\n",
       "Name: sale_date, Length: 6543940, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crmls_closings = pd.concat([pd.read_csv('data/crmls_all_closings0.csv'), pd.read_csv('data/crmls_all_closings1.csv'), \n",
    "                            pd.read_csv('data/crmls_all_closings2.csv'), pd.read_csv('data/crmls_all_closings3.csv'), \n",
    "                            pd.read_csv('data/crmls_all_closings4.csv'), pd.read_csv('data/crmls_all_closings5.csv')])\n",
    "print(len(crmls_closings))\n",
    "crmls_closings['sale_date'] = pd.to_datetime(crmls_closings['sale_date'], errors='coerce')\n",
    "#crmls_closings.dropna(subset='sale_date',inplace=True)\n",
    "#crmls_closings['sale_date'] = pd.to_datetime(crmls_closings['sale_date'])\n",
    "crmls_closings['sale_date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#crmls_closings[~pd.isna(crmls_closings['building_id'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#crmls_closings[~crmls_closings['id'].isin(lh['listing_id'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crmls_closings = crmls_closings.merge(lh, how='left', left_on='id', right_on='listing_id')\n",
    "crmls_closings['address_check'] = crmls_closings['display_address'].combine_first(crmls_closings['address'])\n",
    "crmls_closings['zip_check'] = crmls_closings['zip'].combine_first(crmls_closings['zip-2'])\n",
    "crmls_closings['sale_date'] = crmls_closings['update_transaction'].combine_first(crmls_closings['sale_date'])\n",
    "crmls_closings['sale_price'] = crmls_closings['price'].combine_first(crmls_closings['sale_price'])\n",
    "crmls_closings = crmls_closings[['id', 'rebny_id', 'building_id', 'sale_date', 'sale_price', 'address_check', 'zip_check']]\n",
    "crmls_closings.columns = ['id', 'rebny_id', 'building_id', 'listings_sale_date', 'listings_sale_price', 'address', 'zip']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>rebny_id</th>\n",
       "      <th>building_id</th>\n",
       "      <th>listings_sale_date</th>\n",
       "      <th>listings_sale_price</th>\n",
       "      <th>address</th>\n",
       "      <th>zip</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3316490</td>\n",
       "      <td>HD22036424:CRM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-04-11 04:00:00</td>\n",
       "      <td>17000.0</td>\n",
       "      <td>1527 Kittyhawk Street</td>\n",
       "      <td>92274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3316491</td>\n",
       "      <td>SR21249835:CRM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-10-16 04:00:00</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>0 Longview Rd  s/o Old Homestead Rd</td>\n",
       "      <td>93543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3316494</td>\n",
       "      <td>HD22057614:CRM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-08-15 04:00:00</td>\n",
       "      <td>48000.0</td>\n",
       "      <td>0 View Crest</td>\n",
       "      <td>92257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3316506</td>\n",
       "      <td>OC20002047:CRM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-06-05 04:00:00</td>\n",
       "      <td>357000.0</td>\n",
       "      <td>0 Morningfield Drive</td>\n",
       "      <td>91709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3316514</td>\n",
       "      <td>SR21155219:CRM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-05-19 04:00:00</td>\n",
       "      <td>36000.0</td>\n",
       "      <td>10313 Caribou Lane</td>\n",
       "      <td>90077</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id        rebny_id  building_id  listings_sale_date  \\\n",
       "0  3316490  HD22036424:CRM          NaN 2024-04-11 04:00:00   \n",
       "1  3316491  SR21249835:CRM          NaN 2023-10-16 04:00:00   \n",
       "2  3316494  HD22057614:CRM          NaN 2023-08-15 04:00:00   \n",
       "3  3316506  OC20002047:CRM          NaN 2023-06-05 04:00:00   \n",
       "4  3316514  SR21155219:CRM          NaN 2022-05-19 04:00:00   \n",
       "\n",
       "   listings_sale_price                              address    zip  \n",
       "0              17000.0                1527 Kittyhawk Street  92274  \n",
       "1              30000.0  0 Longview Rd  s/o Old Homestead Rd  93543  \n",
       "2              48000.0                         0 View Crest  92257  \n",
       "3             357000.0                 0 Morningfield Drive  91709  \n",
       "4              36000.0                   10313 Caribou Lane  90077  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crmls_closings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_round_match(first_match, off_market_sales, day_threshold: tuple, price_threshold: tuple):\n",
    "    first_match['match_key'] = [str(x).upper() for x in first_match['address']]\n",
    "    first_match = first_match.merge(off_market_sales, how='inner', left_on='match_key', right_on='propertyfullstreetaddress')\n",
    "    #print(f\"matches before thresholds: {first_match['id'].nunique()}\")\n",
    "    #first_match['listings_sale_price'] = pd.to_numeric(first_match['listings_sale_price'])\n",
    "    #first_match['salesprice'] = pd.to_numeric(first_match['salesprice'])\n",
    "    first_match = first_match.dropna(subset=['listings_sale_date', 'recordingdate', 'salesprice', 'listings_sale_price'])\n",
    "    if price_threshold[1]:\n",
    "        if day_threshold[1]:\n",
    "            first_match = first_match[(abs(first_match['listings_sale_date'] - first_match['recordingdate']) < day_threshold[1])\n",
    "                              & (abs(first_match['listings_sale_date'] - first_match['recordingdate']) >= day_threshold[0])\n",
    "                              & (abs((first_match['listings_sale_price'] - first_match['salesprice'])/first_match['listings_sale_price']) < price_threshold[1])\n",
    "                              & (abs((first_match['listings_sale_price'] - first_match['salesprice'])/first_match['listings_sale_price']) >= price_threshold[0])]\n",
    "        else:\n",
    "            first_match = first_match[\n",
    "                              (abs(first_match['listings_sale_date'] - first_match['recordingdate']) >= day_threshold[0])\n",
    "                              & (abs((first_match['listings_sale_price'] - first_match['salesprice'])/first_match['listings_sale_price']) < price_threshold[1])\n",
    "                              & (abs((first_match['listings_sale_price'] - first_match['salesprice'])/first_match['listings_sale_price']) >= price_threshold[0])]\n",
    "    else:\n",
    "        if day_threshold[1]:\n",
    "            first_match = first_match[(abs(first_match['listings_sale_date'] - first_match['recordingdate']) < day_threshold[1])\n",
    "                              & (abs(first_match['listings_sale_date'] - first_match['recordingdate']) >= day_threshold[0])\n",
    "                              & (abs((first_match['listings_sale_price'] - first_match['salesprice'])/first_match['listings_sale_price']) >= price_threshold[0])]\n",
    "        else:\n",
    "            first_match = first_match[(abs(first_match['listings_sale_date'] - first_match['recordingdate']) >= day_threshold[0])\n",
    "                              & (abs((first_match['listings_sale_price'] - first_match['salesprice'])/first_match['listings_sale_price']) >= price_threshold[0])]\n",
    "    return first_match[['id', 'bk_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_dict = {'ALLEE': 'ALY', 'ALLEY': 'ALY', 'ALLY': 'ALY', 'ALY': 'ALY',\n",
    "             'ANEX': 'ANX', 'ANNEX': 'ANX', 'ANNX': 'ANX', 'ANX': 'ANX',\n",
    "'ARC': 'ARC', 'ARCADE': 'ARC', 'AV': 'AVE', 'AVE': 'AVE', 'AVEN': 'AVE',\n",
    "'AVENU': 'AVE', 'AVENUE': 'AVE', 'AVN': 'AVE', 'AVNUE': 'AVE', 'BAYOO': 'BYU',\n",
    "'BAYOU': 'BYU', 'BCH': 'BCH', 'BEACH': 'BCH', 'BEND': 'BND', 'BND': 'BND',\n",
    "'BLF': 'BLF', 'BLUF': 'BLF', 'BLUFF': 'BLF', 'BLUFFS': 'BLFS', 'BOT': 'BTM',\n",
    "'BTM': 'BTM', 'BOTTM': 'BTM', 'BOTTOM': 'BTM', 'BLVD': 'BLVD', 'BOUL': 'BLVD',\n",
    "'BOULEVARD': 'BLVD', 'BOULV': 'BLVD', 'BR': 'BR', 'BRNCH': 'BR','BRANCH': 'BR',\n",
    "'BRDGE': 'BRG', 'BRG': 'BRG', 'BRIDGE': 'BRG', 'BRK': 'BRK', 'BROOK': 'BRK',\n",
    "'BROOKS': 'BRKS', 'BURG': 'BG', 'BURGS': 'BGS', 'BYP': 'BYP', 'BYPA': 'BYP',\n",
    "'BYPAS': 'BYP', 'BYPASS': 'BYP', 'BYPS': 'BYP', 'CAMP': 'CP', 'CP': 'CP',\n",
    "'CMP': 'CP', 'CANYN': 'CYN', 'CANYON': 'CYN', 'CNYN': 'CYN', 'CAPE': 'CPE',\n",
    "'CPE': 'CPE', 'CAUSEWAY': 'CSWY', 'CAUSWA': 'CSWY', 'CSWY': 'CSWY',\n",
    "'CEN': 'CTR', 'CENT': 'CTR', 'CENTER': 'CTR', 'CENTR': 'CTR', 'CENTRE': 'CTR',\n",
    "'CNTER': 'CTR', 'CNTR': 'CTR', 'CTR': 'CTR', 'CENTERS': 'CTRS', 'CIR': 'CIR',\n",
    "'CIRC': 'CIR', 'CIRCL': 'CIR', 'CIRCLE': 'CIR', 'CRCL': 'CIR', 'CRCLE': 'CIR',\n",
    "'CIRCLES': 'CIRS', 'CLF': 'CLF', 'CLIFF': 'CLF', 'CLFS': 'CLFS',\n",
    "'CLIFFS': 'CLFS','CLB': 'CLB', 'CLUB': 'CLB', 'COMMON': 'CMN',\n",
    "'COMMONS': 'CMNS', 'COR': 'COR','CORNER': 'COR', 'CORNERS': 'CORS',\n",
    "'CORS': 'CORS', 'COURSE': 'CRSE', 'CRSE': 'CRSE','COURT': 'CT', 'CT': 'CT',\n",
    "'COURTS': 'CTS', 'CTS': 'CTS', 'COVE': 'CV', 'CV': 'CV', 'COVES': 'CVS',\n",
    " 'CREEK': 'CRK', 'CRK': 'CRK', 'CRESCENT': 'CRES', 'CRES': 'CRES',\n",
    "'CRSENT': 'CRES', 'CRSNT': 'CRES', 'CREST': 'CRST', 'CROSSING': 'XING',\n",
    "'CRSSNG': 'XING', 'XING': 'XING', 'CROSSROAD': 'XRD', 'CROSSROADS': 'XRDS',\n",
    "'CURVE': 'CURV', 'DALE': 'DL', 'DL': 'DL', 'DAM': 'DM', 'DM': 'DM',\n",
    "'DIV': 'DV', 'DIVIDE': 'DV', 'DV': 'DV', 'DVD': 'DV', 'DR': 'DR', 'DRIV': 'DR',\n",
    "'DRIVE': 'DR', 'DRV': 'DR', 'DRIVES': 'DRS', 'EST': 'EST', 'ESTATE': 'EST',\n",
    "'ESTATES': 'ESTS', 'ESTS': 'ESTS', 'EXP': 'EXPY', 'EXPR': 'EXPY',\n",
    "'EXPRESS': 'EXPY', 'EXPRESSWAY': 'EXPY', 'EXPW': 'EXPY', 'EXPY': 'EXPY',\n",
    "'EXT': 'EXT', 'EXTENSION': 'EXT', 'EXTN': 'EXT', 'EXTNSN': 'EXT',\n",
    "'EXTS': 'EXTS', 'FALL': 'FALL', 'FALLS': 'FLS', 'FLS': 'FLS', 'FERRY': 'FRY',\n",
    "'FRRY': 'FRY', 'FRY': 'FRY', 'FIELD': 'FLD', 'FLD': 'FLD', 'FIELDS': 'FLDS',\n",
    "'FLDS': 'FLDS', 'FLAT': 'FLT', 'FLT': 'FLT', 'FLATS': 'FLTS', 'FLTS': 'FLTS',\n",
    "'FORD': 'FRD', 'FRD': 'FRD', 'FORDS': 'FRDS', 'FOREST': 'FRST',\n",
    "'FORESTS': 'FRST', 'FRST': 'FRST', 'FORG': 'FRG', 'FORGE': 'FRG',\n",
    "'FRG': 'FRG', 'FORGES': 'FRGS', 'FORK': 'FRK', 'FRK': 'FRK', 'FORKS': 'FRKS',\n",
    "'FRKS': 'FRKS', 'FORT': 'FT', 'FRT': 'FT', 'FT': 'FT', 'FREEWAY': 'FWY',\n",
    "'FREEWY': 'FWY', 'FRWAY': 'FWY', 'FRWY': 'FWY', 'FWY': 'FWY', 'GARDEN': 'GDN',\n",
    "'GARDN': 'GDN', 'GRDEN': 'GDN', 'GRDN': 'GDN', 'GARDENS': 'GDNS',\n",
    "'GDNS': 'GDNS', 'GRDNS': 'GDNS', 'GATEWAY': 'GTWY', 'GATEWY': 'GTWY',\n",
    "'GATWAY': 'GTWY', 'GTWAY': 'GTWY', 'GTWY': 'GTWY', 'GLEN': 'GLN',\n",
    "'GLN': 'GLN', 'GLENS': 'GLNS', 'GREEN': 'GRN', 'GRN': 'GRN',\n",
    "'GREENS': 'GRNS', 'GROV': 'GRV', 'GROVE': 'GRV', 'GRV': 'GRV',\n",
    "'GROVES': 'GRVS', 'HARB': 'HBR', 'HARBOR': 'HBR', 'HARBR': 'HBR', 'HBR': 'HBR',\n",
    "'HRBOR': 'HBR', 'HARBORS': 'HBRS', 'HAVEN': 'HVN', 'HVN': 'HVN',\n",
    "'HT': 'HTS', 'HTS': 'HTS', 'HIGHWAY': 'HWY', 'HIGHWY': 'HWY', 'HIWAY': 'HWY',\n",
    "'HIWY': 'HWY', 'HWAY': 'HWY', 'HWY': 'HWY', 'HILL': 'HL', 'HL': 'HL',\n",
    "'HILLS': 'HLS', 'HLS': 'HLS', 'HLLW': 'HOLW', 'HOLLOW': 'HOLW',\n",
    "'HOLLOWS': 'HOLW', 'HOLW': 'HOLW', 'HOLWS': 'HOLW', 'INLT': 'INLT',\n",
    "'IS': 'IS', 'ISLAND': 'IS', 'ISLND': 'IS', 'ISLANDS': 'ISS', 'ISLNDS': 'ISS',\n",
    "'ISS': 'ISS', 'ISLE': 'ISLE', 'ISLES': 'ISLE', 'JCT': 'JCT', 'JCTION': 'JCT',\n",
    "'JCTN': 'JCT', 'JUNCTION': 'JCT', 'JUNCTN': 'JCT', 'JUNCTON': 'JCT',\n",
    "'JCTNS': 'JCTS', 'JCTS': 'JCTS', 'JUNCTIONS': 'JCTS', 'KEY': 'KY',\n",
    "'KY': 'KY', 'KEYS': 'KYS', 'KYS': 'KYS', 'KNL': 'KNL', 'KNOL': 'KNL',\n",
    "'KNOLL': 'KNL', 'KNLS': 'KNLS', 'KNOLLS': 'KNLS', 'LK': 'LK', 'LAKE': 'LK',\n",
    "'LKS': 'LKS', 'LAKES': 'LKS', 'LAND': 'LAND', 'LANDING': 'LNDG',\n",
    "'LNDG': 'LNDG', 'LNDNG': 'LNDG', 'LANE': 'LN', 'LN': 'LN', 'LGT': 'LGT',\n",
    "'LIGHT': 'LGT', 'LIGHTS': 'LGTS', 'LF': 'LF', 'LOAF': 'LF', 'LCK': 'LCK',\n",
    "'LOCK': 'LCK', 'LCKS': 'LCKS', 'LOCKS': 'LCKS', 'LDG': 'LDG', 'LDGE': 'LDG',\n",
    "'LODG': 'LDG', 'LODGE': 'LDG', 'LOOP': 'LOOP', 'LOOPS': 'LOOP', 'MALL': 'MALL',\n",
    "'MNR': 'MNR', 'MANOR': 'MNR', 'MANORS': 'MNRS', 'MNRS': 'MNRS', 'MEADOW': 'MDW',\n",
    "'MDW': 'MDWS', 'MDWS': 'MDWS', 'MEADOWS': 'MDWS', 'MEDOWS': 'MDWS',\n",
    "'MEWS': 'MEWS', 'MILL': 'ML', 'MILLS': 'MLS', 'MISSN': 'MSN', 'MSSN': 'MSN',\n",
    "'MOTORWAY': 'MTWY', 'MNT': 'MT', 'MT': 'MT', 'MOUNT': 'MT', 'MNTAIN': 'MTN',\n",
    "'MNTN': 'MTN', 'MOUNTAIN': 'MTN', 'MOUNTIN': 'MTN', 'MTIN': 'MTN',\n",
    "'MTN': 'MTN', 'MNTNS': 'MTNS', 'MOUNTAINS': 'MTNS', 'NCK': 'NCK',\n",
    "'NECK': 'NCK', 'ORCH': 'ORCH', 'ORCHARD': 'ORCH', 'ORCHRD': 'ORCH',\n",
    "'OVAL': 'OVAL', 'OVL': 'OVAL', 'OVERPASS': 'OPAS', 'PARK': 'PARK',\n",
    "'PRK': 'PARK', 'PARKS': 'PARK', 'PARKWAY': 'PKWY', 'PARKWY': 'PKWY',\n",
    "'PKWAY': 'PKWY', 'PKWY': 'PKWY', 'PKY': 'PKWY', 'PARKWAYS': 'PKWY',\n",
    "'PKWYS': 'PKWY', 'PASS': 'PASS', 'PASSAGE': 'PSGE', 'PATH': 'PATH',\n",
    "'PATHS': 'PATH', 'PIKE': 'PIKE', 'PIKES': 'PIKE', 'PINE': 'PNE',\n",
    "'PINES': 'PNES', 'PNES': 'PNES', 'PL': 'PL', 'PLAIN': 'PLN', 'PLN': 'PLN',\n",
    "'PLAINS': 'PLNS', 'PLNS': 'PLNS', 'PLAZA': 'PLZ', 'PLZ': 'PLZ', 'PLZA': 'PLZ',\n",
    "'POINT': 'PT', 'PT': 'PT', 'POINTS': 'PTS', 'PTS': 'PTS', 'PORT': 'PRT',\n",
    "'PRT': 'PRT', 'PORTS': 'PRTS', 'PRTS': 'PRTS', 'PR': 'PR', 'PRAIRIE': 'PR',\n",
    "'PRR': 'PR', 'RAD': 'RADL', 'RADIAL': 'RADL', 'RADIEL': 'RADL',\n",
    "'RADL': 'RADL', 'RAMP': 'RAMP', 'RANCH': 'RNCH', 'RANCHES': 'RNCH',\n",
    "'RNCH': 'RNCH', 'RNCHS': 'RNCH', 'RAPID': 'RPD', 'RPD': 'RPD',\n",
    "'RAPIDS': 'RPDS', 'RPDS': 'RPDS', 'REST': 'RST', 'RST': 'RST', 'RDG': 'RDG',\n",
    "'RDGE': 'RDG', 'RIDGE': 'RDG', 'RDGS': 'RDGS', 'RIDGES': 'RDGS', 'RIV': 'RIV',\n",
    "'RIVER': 'RIV', 'RVR': 'RIV', 'RIVR': 'RIV', 'RD': 'RD', 'ROAD': 'RD',\n",
    "'ROADS': 'RDS', 'RDS': 'RDS', 'ROUTE': 'RTE', 'ROW': 'ROW', 'RUE': 'RUE',\n",
    "'RUN': 'RUN', 'SHL': 'SHL', 'SHOAL': 'SHL', 'SHLS': 'SHLS', 'SHOALS': 'SHLS',\n",
    "'SHOAR': 'SHR', 'SHORE': 'SHR', 'SHR': 'SHR', 'SHOARS': 'SHRS',\n",
    "'SHORES': 'SHRS', 'SHRS': 'SHRS', 'SKYWAY': 'SKWY', 'SPG': 'SPG',\n",
    "'SPNG': 'SPG', 'SPRING': 'SPG', 'SPRNG': 'SPG', 'SPGS': 'SPGS',\n",
    "'SPNGS': 'SPGS', 'SPRINGS': 'SPGS', 'SPRNGS': 'SPGS', 'SPUR': 'SPUR',\n",
    "'SPURS': 'SPUR', 'SQ': 'SQ', 'SQR': 'SQ', 'SQRE': 'SQ', 'SQU': 'SQ',\n",
    "'SQUARE': 'SQ', 'SQRS': 'SQS', 'SQUARES': 'SQS', 'STA': 'STA',\n",
    "'STATION': 'STA', 'STATN': 'STA', 'STN': 'STA', 'STRA': 'STRA',\n",
    "'STRAV': 'STRA', 'STRAVEN': 'STRA', 'STRAVENUE': 'STRA', 'STRAVN': 'STRA',\n",
    "'STRVN': 'STRA', 'STRVNUE': 'STRA', 'STREAM': 'STRM', 'STREME': 'STRM',\n",
    "'STRM': 'STRM', 'STREET': 'ST', 'STRT': 'ST', 'ST': 'ST', 'STR': 'ST',\n",
    "'STREETS': 'STS', 'SMT': 'SMT', 'SUMIT': 'SMT', 'SUMITT': 'SMT',\n",
    "'SUMMIT': 'SMT', 'TER': 'TER', 'TERR': 'TER', 'TERRACE': 'TER',\n",
    "'THROUGHWAY': 'TRWY', 'TRACE': 'TRCE', 'TRACES': 'TRCE', 'TRCE': 'TRCE',\n",
    "'TRACK': 'TRAK', 'TRACKS': 'TRAK', 'TRAK': 'TRAK', 'TRK': 'TRAK',\n",
    "'TRKS': 'TRAK', 'TRAFFICWAY': 'TRFY', 'TRAIL': 'TRL', 'TRAILS': 'TRL',\n",
    "'TRL': 'TRL', 'TRLS': 'TRL', 'TRAILER': 'TRLR', 'TRLR': 'TRLR',\n",
    "'TRLRS': 'TRLR', 'TUNEL': 'TUNL', 'TUNL': 'TUNL', 'TUNLS': 'TUNL',\n",
    "'TUNNEL': 'TUNL', 'TUNNELS': 'TUNL', 'TUNNL': 'TUNL', 'TRNPK': 'TPKE',\n",
    "'TURNPIKE': 'TPKE', 'TURNPK': 'TPKE', 'UNDERPASS': 'UPAS', 'UN': 'UN',\n",
    "'UNION': 'UN', 'UNIONS': 'UNS', 'VALLEY': 'VLY', 'VALLY': 'VLY',\n",
    "'VLLY': 'VLY', 'VLY': 'VLY', 'VALLEYS': 'VLYS', 'VLYS': 'VLYS',\n",
    "'VDCT': 'VIA', 'VIA': 'VIA', 'VIADCT': 'VIA', 'VIADUCT': 'VIA',\n",
    "'VIEW': 'VW', 'VW': 'VW', 'VIEWS': 'VWS', 'VWS': 'VWS', 'VILL': 'VLG',\n",
    "'VILLAG': 'VLG', 'VILLAGE': 'VLG', 'VILLG': 'VLG', 'VILLIAGE': 'VLG',\n",
    "'VLG': 'VLG', 'VILLAGES': 'VLGS', 'VLGS': 'VLGS', 'VILLE': 'VL',\n",
    "'VL': 'VL', 'VIS': 'VIS', 'VIST': 'VIS', 'VISTA': 'VIS', 'VST': 'VIS',\n",
    "'VSTA': 'VIS', 'WALK': 'WALK', 'WALKS': 'WALK', 'WALL': 'WALL', 'WY': 'WAY',\n",
    "'WAY': 'WAY', 'WAYS': 'WAYS', 'WELL': 'WL', 'WELLS': 'WLS', 'WLS': 'WLS',\n",
    "'PLACE': 'PL', 'NORTH': 'N', 'NORTHEAST': 'NE', 'NORTHWEST': 'NW',\n",
    "'SOUTH': 'S', 'SOUTHEAST': 'SE', 'SOUTHWEST': 'SW', 'EAST': 'E', 'WEST': 'W'}\n",
    "\n",
    "def standardize_address(address: str) -> str:\n",
    "    address = address.upper()\n",
    "    address = address.replace('(', '')\n",
    "    address = address.replace(')', '')\n",
    "    address = address.replace('#', '')\n",
    "    address = address.replace('UNIT', '')\n",
    "    address = address.replace('STE', '')\n",
    "    address = address.replace('  ', ' ')\n",
    "    address_split = address.split()\n",
    "    for i in range(len(address_split)):\n",
    "        if address_split[i] in map_dict.keys():\n",
    "            address_split[i] = map_dict[address_split[i]]\n",
    "    #for index, row in suffixes.iterrows():\n",
    "     #   if ' ' + row['Alias'] in address:\n",
    "      #      address = address.replace(row['Alias'], row['Abbreviation'])\n",
    "    return ' '.join(address_split)\n",
    "\n",
    "def second_round_match(second_match, off_market_sales, day_threshold, price_threshold):\n",
    "    #print('starting second match')\n",
    "    #suffixes = pd.read_csv(f'{base_fp}/usps street suffixes.csv')\n",
    "    #suffixes.columns = ['Street Suffix', 'Alias', 'Abbreviation']\n",
    "    #suffixes.fillna(method='ffill', inplace=True)\n",
    "    #suffixes = suffixes[['Alias', 'Abbreviation']]\n",
    "    second_match['normalized_address'] = [standardize_address(str(x)) for x in second_match['address']]\n",
    "    #second_match['normalized_address'] = second_match['address'].apply(standardize_address(x, suffixes))\n",
    "    off_market_sales['normalized_address'] = [standardize_address(str(x)) for x in off_market_sales['propertyfullstreetaddress']]\n",
    "    #print('second match done cleaning')\n",
    "    second_match = second_match.merge(off_market_sales, how='inner', on='normalized_address')\n",
    "    #print(f\"matches before thresholds: {second_match['id'].nunique()}\")\n",
    "    if price_threshold[1]:\n",
    "        if day_threshold[1]:\n",
    "            second_match = second_match[(abs((second_match['listings_sale_price'] - second_match['salesprice'])/second_match['listings_sale_price']) < price_threshold[1])\n",
    "                                & (abs((second_match['listings_sale_price'] - second_match['salesprice'])/second_match['listings_sale_price']) >= price_threshold[0])\n",
    "                                & (abs(second_match['listings_sale_date'] - second_match['recordingdate']) < day_threshold[1])\n",
    "                                & (abs(second_match['listings_sale_date'] - second_match['recordingdate']) >= day_threshold[0])]\n",
    "        else:\n",
    "            second_match = second_match[(abs((second_match['listings_sale_price'] - second_match['salesprice'])/second_match['listings_sale_price']) < price_threshold[1])\n",
    "                                & (abs((second_match['listings_sale_price'] - second_match['salesprice'])/second_match['listings_sale_price']) >= price_threshold[0])\n",
    "                                & (abs(second_match['listings_sale_date'] - second_match['recordingdate']) >= day_threshold[0])]\n",
    "    else:\n",
    "        if day_threshold[1]:\n",
    "            second_match = second_match[\n",
    "                                (abs((second_match['listings_sale_price'] - second_match['salesprice'])/second_match['listings_sale_price']) >= price_threshold[0])\n",
    "                                & (abs(second_match['listings_sale_date'] - second_match['recordingdate']) < day_threshold[1])\n",
    "                                & (abs(second_match['listings_sale_date'] - second_match['recordingdate']) >= day_threshold[0])]\n",
    "        else:\n",
    "            second_match = second_match[\n",
    "                                (abs((second_match['listings_sale_price'] - second_match['salesprice'])/second_match['listings_sale_price']) >= price_threshold[0])\n",
    "                                & (abs(second_match['listings_sale_date'] - second_match['recordingdate']) >= day_threshold[0])]\n",
    "    \n",
    "    return second_match[['id', 'bk_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fuzzy_match(lb_address: str, lb_street_name: str, pw_address: str, listing_id, lb_price, pw_price, lb_date, pw_date, day_threshold, price_threshold): #, lb_zip, pw_zip):\n",
    "    l = lb_address.strip().split()\n",
    "    p = pw_address.strip().split()\n",
    "    m_count = 0\n",
    "\n",
    "    if not ((l[0] == p[0]) and (str(lb_street_name) in pw_address)):\n",
    "        return None\n",
    "    \n",
    "    if len(l) >= len(p):\n",
    "        len_address = len(p)\n",
    "        for i in l:\n",
    "            if i in p: m_count += 1\n",
    "    else:\n",
    "        len_address = len(l)\n",
    "        for i in p:\n",
    "            if i in l: m_count += 1\n",
    "    try:\n",
    "        if price_threshold[1]:\n",
    "            if day_threshold[1]:\n",
    "                if (m_count / len_address >= 0.66) \\\n",
    "                    and (abs((lb_price - pw_price) / pw_price) < price_threshold[1])\\\n",
    "                        and (abs((lb_price - pw_price) / pw_price) >= price_threshold[0])\\\n",
    "                            and (abs(pw_date - lb_date) < day_threshold[1])\\\n",
    "                                and (abs(pw_date - lb_date) >= day_threshold[0]):\n",
    "                    return listing_id\n",
    "                else:\n",
    "                    return None\n",
    "            else:\n",
    "                if (m_count / len_address >= 0.66) \\\n",
    "                    and (abs((lb_price - pw_price) / pw_price) < price_threshold[1])\\\n",
    "                        and (abs((lb_price - pw_price) / pw_price) >= price_threshold[0])\\\n",
    "                                and (abs(pw_date - lb_date) >= day_threshold[0]):\n",
    "                    return listing_id\n",
    "                else:\n",
    "                    return None\n",
    "\n",
    "        else:\n",
    "            if day_threshold[1]:\n",
    "                if (m_count / len_address >= 0.66) \\\n",
    "                        and (abs((lb_price - pw_price) / pw_price) >= price_threshold[0])\\\n",
    "                            and (abs(pw_date - lb_date) < day_threshold[1])\\\n",
    "                                and (abs(pw_date - lb_date) >= day_threshold[0]):\n",
    "                    return listing_id\n",
    "                else:\n",
    "                    return None\n",
    "            else:\n",
    "                if (m_count / len_address >= 0.66) \\\n",
    "                        and (abs((lb_price - pw_price) / pw_price) >= price_threshold[0])\\\n",
    "                                and (abs(pw_date - lb_date) >= day_threshold[0]):\n",
    "                    return listing_id\n",
    "                else:\n",
    "                    return None\n",
    "    except ZeroDivisionError:\n",
    "        return None\n",
    "\n",
    "def try_to_int(s):\n",
    "    try:\n",
    "        if '-' in str(s):\n",
    "            return int(s.split('-')[0])\n",
    "        else:\n",
    "            return int(s)\n",
    "    except ValueError:\n",
    "        return None\n",
    "\n",
    "\n",
    "def third_round_match(third_match, off_market_sales, day_threshold, price_threshold):\n",
    "    third_match['check_zip'] = [try_to_int(x) for x in third_match['zip']]\n",
    "    third_match = third_match.dropna(subset='zip')\n",
    "    off_market_sales['streetname'] = [str(x).replace(str(y), '').strip() if y else str(x) for x, y in zip(off_market_sales['propertyfullstreetaddress'], off_market_sales['propertyhousenumber'])]\n",
    "    third_match['normalized_address'] = [standardize_address(str(x)) for x in third_match['address']]\n",
    "    off_market_sales['normalized_address'] = [standardize_address(str(x)) for x in off_market_sales['propertyfullstreetaddress']]\n",
    "    retlist = []\n",
    "    for lb_address, lb_price, lb_date, lb_street_name, lb_zip in tqdm(zip(off_market_sales['normalized_address'],\n",
    "                                                          off_market_sales['salesprice'],\n",
    "                                                          off_market_sales['recordingdate'], \n",
    "                                                          off_market_sales['streetname'], \n",
    "                                                          off_market_sales['propertyzipcode']), \n",
    "                                                          total=len(off_market_sales), leave=True):\n",
    "    #for lb_address, lb_price, lb_date, lb_zip in zip(off_market_sales['normalized_address'], off_market_sales['VAL_TRANSFER'], off_market_sales['DATE_TRANSFER'], off_market_sales['SITE_ZIP']):\n",
    "        #if len(retlist)%10000 == 0:\n",
    "         #   #print(len(retlist), len(off_market_sales))\n",
    "        check = third_match[third_match['check_zip'] == lb_zip]\n",
    "        found = False\n",
    "        for pw_address, pw_price, pw_date, l_id in zip(check['normalized_address'], check['listings_sale_price'], check['listings_sale_date'], check['id']):\n",
    "            result = fuzzy_match(lb_address, lb_street_name, pw_address, l_id, lb_price, pw_price, lb_date, pw_date, day_threshold, price_threshold)\n",
    "            if result:\n",
    "                found = True\n",
    "                retlist.append(result)\n",
    "                break\n",
    "        if not found:\n",
    "            retlist.append(None)\n",
    "\n",
    "    off_market_sales['matched_listing_id'] = retlist\n",
    "    off_market_sales[~pd.isna(off_market_sales['matched_listing_id'])].merge(third_match, how='inner', left_on='matched_listing_id', right_on='id').to_csv(f'data/fuzzy_matches.csv')\n",
    "    return off_market_sales[~pd.isna(off_market_sales['matched_listing_id'])][['matched_listing_id', 'bk_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold_match(pw_closings: pd.DataFrame, lb_deeds: pd.DataFrame,\n",
    "                     day_threshold: tuple, price_threshold: tuple) -> pd.DataFrame:\n",
    "    \n",
    "    matched_pw_ids = []\n",
    "    matched_lb_ids = []\n",
    "    pw_closings['check_zip'] = [try_to_int(x) for x in pw_closings['zip']]\n",
    "    for pw_zip, pw_price, pw_date, pw_id in tqdm(zip(pw_closings['check_zip'], pw_closings['listings_sale_price'], pw_closings['listings_sale_date'], pw_closings['id']), total=len(pw_closings)):\n",
    "        check = lb_deeds[lb_deeds['propertyzipcode'] == pw_zip]\n",
    "        found_lb_id = []\n",
    "        try:\n",
    "            for lb_price, lb_date, lb_id in zip(check['salesprice'], check['recordingdate'], check['bk_id']):\n",
    "                    if ((price_threshold[0] <= (abs(pw_price - lb_price)/pw_price) < price_threshold[1]) \n",
    "                        and (day_threshold[0] <= abs(pw_date - lb_date) < day_threshold[1])):\n",
    "\n",
    "                        found_lb_id.append(lb_id)\n",
    "        \n",
    "        except (ZeroDivisionError, TypeError):\n",
    "            continue\n",
    "\n",
    "        if len(found_lb_id) >= 0:\n",
    "            matched_pw_ids += [pw_id] * len(found_lb_id)\n",
    "            matched_lb_ids += found_lb_id\n",
    "    \n",
    "    return pd.DataFrame({'id': matched_pw_ids, 'bk_id': matched_lb_ids})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "day_thresh = [timedelta(days=0), timedelta(days=14), timedelta(days=30), timedelta(days=90), timedelta(days=180), timedelta(days=365), timedelta(days=520), None]\n",
    "price_thresh = [0, 0.1, 0.3, 0.6, 1, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    with open('data/matches_buckets.pkl', 'rb') as f:\n",
    "        retdict = pkl.load(f)\n",
    "except:\n",
    "    retdict = {}\n",
    "    \n",
    "with open('data/unmatched_closings.pkl', 'rb') as f:\n",
    "      crmls_closings = pkl.load(f)\n",
    "with open('data/unmatched_deeds.pkl', 'rb') as f:\n",
    "      bk_deeds = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    with open('data/matches_buckets.pkl', 'rb') as f:\n",
    "        retdict = pkl.load(f)\n",
    "except:\n",
    "    retdict = {}\n",
    "    \n",
    "with open('data/unmatched_closings.pkl', 'rb') as f:\n",
    "      crmls_closings = pkl.load(f)\n",
    "with open('data/unmatched_deeds.pkl', 'rb') as f:\n",
    "      bk_deeds = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "221a74cc95614ad6a0265b223b393baf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "761b5d51817243a38a6df3f605a80d98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((datetime.timedelta(0), datetime.timedelta(days=14)), (0, 0.1)) 5027211\n",
      "((datetime.timedelta(0), datetime.timedelta(days=14)), (0.1, 0.3)) 21861\n",
      "((datetime.timedelta(0), datetime.timedelta(days=14)), (0.3, 0.6)) 13729\n",
      "((datetime.timedelta(0), datetime.timedelta(days=14)), (0.6, 1)) 8373\n",
      "((datetime.timedelta(0), datetime.timedelta(days=14)), (1, None)) 9676\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1749029d0620498f9aa56223b154e67e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((datetime.timedelta(days=14), datetime.timedelta(days=30)), (0, 0.1)) 101231\n",
      "((datetime.timedelta(days=14), datetime.timedelta(days=30)), (0.1, 0.3)) 3048\n",
      "((datetime.timedelta(days=14), datetime.timedelta(days=30)), (0.3, 0.6)) 1429\n",
      "((datetime.timedelta(days=14), datetime.timedelta(days=30)), (0.6, 1)) 969\n",
      "((datetime.timedelta(days=14), datetime.timedelta(days=30)), (1, None)) 767\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aff057085a0c47439d4f5ee4af757ddf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((datetime.timedelta(days=30), datetime.timedelta(days=90)), (0, 0.1)) 84902\n",
      "((datetime.timedelta(days=30), datetime.timedelta(days=90)), (0.1, 0.3)) 5506\n",
      "((datetime.timedelta(days=30), datetime.timedelta(days=90)), (0.3, 0.6)) 2603\n",
      "((datetime.timedelta(days=30), datetime.timedelta(days=90)), (0.6, 1)) 1835\n",
      "((datetime.timedelta(days=30), datetime.timedelta(days=90)), (1, None)) 1530\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4e4e0c00bca4decb11bb103e2b2f8ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((datetime.timedelta(days=90), datetime.timedelta(days=180)), (0, 0.1)) 11966\n",
      "((datetime.timedelta(days=90), datetime.timedelta(days=180)), (0.1, 0.3)) 5340\n",
      "((datetime.timedelta(days=90), datetime.timedelta(days=180)), (0.3, 0.6)) 2978\n",
      "((datetime.timedelta(days=90), datetime.timedelta(days=180)), (0.6, 1)) 2059\n",
      "((datetime.timedelta(days=90), datetime.timedelta(days=180)), (1, None)) 1520\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0da4816157ce4c339427ebd1831d556c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((datetime.timedelta(days=180), datetime.timedelta(days=365)), (0, 0.1)) 6874\n",
      "((datetime.timedelta(days=180), datetime.timedelta(days=365)), (0.1, 0.3)) 6614\n",
      "((datetime.timedelta(days=180), datetime.timedelta(days=365)), (0.3, 0.6)) 4515\n",
      "((datetime.timedelta(days=180), datetime.timedelta(days=365)), (0.6, 1)) 3226\n",
      "((datetime.timedelta(days=180), datetime.timedelta(days=365)), (1, None)) 2540\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffd59d3311814b9f8bc0bc14260cc5fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((datetime.timedelta(days=365), datetime.timedelta(days=520)), (0, 0.1)) 2711\n",
      "((datetime.timedelta(days=365), datetime.timedelta(days=520)), (0.1, 0.3)) 3949\n",
      "((datetime.timedelta(days=365), datetime.timedelta(days=520)), (0.3, 0.6)) 2903\n",
      "((datetime.timedelta(days=365), datetime.timedelta(days=520)), (0.6, 1)) 1984\n",
      "((datetime.timedelta(days=365), datetime.timedelta(days=520)), (1, None)) 1724\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f572f51df6e341308b5365233d734a05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((datetime.timedelta(days=520), None), (0, 0.1)) 46759\n",
      "((datetime.timedelta(days=520), None), (0.1, 0.3)) 44141\n",
      "((datetime.timedelta(days=520), None), (0.3, 0.6)) 56531\n",
      "((datetime.timedelta(days=520), None), (0.6, 1)) 51376\n",
      "((datetime.timedelta(days=520), None), (1, None)) 66781\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(len(day_thresh)-1)):\n",
    "    for j in tqdm(range(len(price_thresh)-1),leave=True):\n",
    "        day_range = (day_thresh[i], day_thresh[i+1])\n",
    "        price_range = (price_thresh[j], price_thresh[j+1])\n",
    "        try:\n",
    "            if type(retdict[(day_range, price_range)]) == pd.DataFrame:\n",
    "                print((day_range, price_range), retdict[(day_range, price_range)]['id'].nunique())\n",
    "                pass\n",
    "        except:\n",
    "            first_match = first_round_match(crmls_closings, bk_deeds, day_range, price_range)\n",
    "            first_match['match_type'] = ['1_first']*len(first_match)\n",
    "            second_match = second_round_match(crmls_closings[~crmls_closings['id'].isin(first_match['id'])],\n",
    "                                              bk_deeds[~bk_deeds.bk_id.isin(first_match['bk_id'])], \n",
    "                                              day_range, \n",
    "                                              price_range)\n",
    "            second_match['match_type'] = ['2_second']*len(second_match)\n",
    "            matched = pd.concat([first_match, second_match])\n",
    "            third_match = third_round_match(crmls_closings[~crmls_closings['id'].isin(matched['id'])], \n",
    "                                            bk_deeds[~bk_deeds.bk_id.isin(matched['bk_id'])], \n",
    "                                            day_range, \n",
    "                                            price_range)\n",
    "            third_match['match_type'] = ['3_third']*len(third_match)\n",
    "            third_match.columns = ['id', 'bk_id', 'match_type']\n",
    "            matched = pd.concat([first_match, second_match, third_match])\n",
    "            retdict[(day_range, price_range)] = matched\n",
    "            with open('data/matches_buckets.pkl', 'wb') as f:\n",
    "                pkl.dump(retdict, f)\n",
    "            crmls_closings = crmls_closings[~crmls_closings['id'].isin(matched['id'])]\n",
    "            bk_deeds = bk_deeds[~bk_deeds.bk_id.isin(matched['bk_id'])]\n",
    "            with open('data/unmatched_closings.pkl', 'wb') as f:\n",
    "                pkl.dump(crmls_closings, f)\n",
    "            with open('data/unmatched_deeds.pkl', 'wb') as f:\n",
    "                pkl.dump(bk_deeds, f)\n",
    "            print(day_range, price_range, first_match['id'].nunique() + second_match['id'].nunique() + third_match['id'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"DAY_THRESH = (timedelta(days=0), timedelta(days=180))\\nPRICE_THRESH = (0, None)\\nfirst_match = first_round_match(crmls_closings, bk_deeds, DAY_THRESH, PRICE_THRESH)\\nsecond_match = second_round_match(crmls_closings[~crmls_closings['id'].isin(first_match['id'])], bk_deeds[~bk_deeds.bk_id.isin(first_match['bk_id'])], DAY_THRESH, PRICE_THRESH)\\nmatched = pd.concat([first_match, second_match])\\nthird_match = third_round_match(crmls_closings[~crmls_closings['id'].isin(matched['id'])], bk_deeds[~bk_deeds.bk_id.isin(matched['bk_id'])], DAY_THRESH, PRICE_THRESH)\\nthird_match.columns = ['id', 'bk_id', 'match_type']\\nprint(first_match['id'].nunique() + second_match['id'].nunique() + third_match['id'].nunique())\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DAY_THRESH = (timedelta(days=0), timedelta(days=14))\n",
    "PRICE_THRESH = (0, 0.1)\n",
    "first_match = first_round_match(crmls_closings, bk_deeds, DAY_THRESH, PRICE_THRESH)\n",
    "second_match = second_round_match(crmls_closings[~crmls_closings['id'].isin(first_match['id'])], bk_deeds[~bk_deeds.bk_id.isin(first_match['bk_id'])], DAY_THRESH, PRICE_THRESH)\n",
    "matched = pd.concat([first_match, second_match])\n",
    "third_match = third_round_match(crmls_closings[~crmls_closings['id'].isin(matched['id'])], bk_deeds[~bk_deeds.bk_id.isin(matched['bk_id'])], DAY_THRESH, PRICE_THRESH)\n",
    "third_match.columns = ['id', 'bk_id', 'match_type']\n",
    "print(first_match['id'].nunique() + second_match['id'].nunique() + third_match['id'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "day_thresh = [timedelta(days=0), timedelta(days=7), timedelta(days=14), timedelta(days=30), timedelta(days=60), timedelta(days=90)]\n",
    "price_thresh = [0, 0.05, 0.1, 0.15]\n",
    "\n",
    "try:\n",
    "    with open('data/threshold_matching.pkl', 'rb') as f:\n",
    "        retdict1 = pkl.load(f)\n",
    "except:\n",
    "    retdict1 = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/unmatched_closings.pkl', 'rb') as f:\n",
    "      crmls_closings = pkl.load(f)\n",
    "with open('data/unmatched_deeds.pkl', 'rb') as f:\n",
    "      bk_deeds = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd147565a23b449f85c62c0d03c5fe7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4db5c37c59c6449bac9557c8e869b061",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e847499ca3a4d54967ae3023b58db6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/932771 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(datetime.timedelta(0), datetime.timedelta(days=7)) (0, 0.05) 193863\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4cd8b9605fc4e3bbfef2464f8aea470",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/738908 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(datetime.timedelta(0), datetime.timedelta(days=7)) (0.05, 0.1) 24822\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07401401e8dc4a67a434b657230d8e9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/714086 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(datetime.timedelta(0), datetime.timedelta(days=7)) (0.1, 0.15) 16824\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85ee62e911c74ff0bd4a54f85623c551",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6418906a26af485284f26ca337baaf7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/697262 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(datetime.timedelta(days=7), datetime.timedelta(days=14)) (0, 0.05) 14105\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c50be5a95cf84ae29a413559fcb2534f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/683157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(datetime.timedelta(days=7), datetime.timedelta(days=14)) (0.05, 0.1) 9487\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19494172fa57434cade9daa16909f61a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/673670 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(datetime.timedelta(days=7), datetime.timedelta(days=14)) (0.1, 0.15) 8162\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a342b7b83874cec8ae98bfb998a48d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b736b151b2974ed6a5d08d2e5bafe741",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/665508 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(datetime.timedelta(days=14), datetime.timedelta(days=30)) (0, 0.05) 16092\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "daab92a6e4074836bc9806c76a807a0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/649416 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(datetime.timedelta(days=14), datetime.timedelta(days=30)) (0.05, 0.1) 10212\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b82bde1444144c01a8f1a42fc3fb2501",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/639204 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(datetime.timedelta(days=14), datetime.timedelta(days=30)) (0.1, 0.15) 8205\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "097b69f96fd44563b16cf49f3cc7ad36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a685488301774dd1b6750515cc39c8b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/630999 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(datetime.timedelta(days=30), datetime.timedelta(days=60)) (0, 0.05) 14074\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b214bef34ec34390b2a910efd563be83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/616925 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(datetime.timedelta(days=30), datetime.timedelta(days=60)) (0.05, 0.1) 8147\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29ab1a06bb4843b782d1f158d641ed21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/608778 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(datetime.timedelta(days=30), datetime.timedelta(days=60)) (0.1, 0.15) 6480\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1698f80930dd4484b7eda5a12f37a009",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45acb989e14c411d8cc538888798f576",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/602298 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(datetime.timedelta(days=60), datetime.timedelta(days=90)) (0, 0.05) 7033\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "deeee3ed27904473a2dd768ef3c628ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/595265 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(datetime.timedelta(days=60), datetime.timedelta(days=90)) (0.05, 0.1) 4360\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91e33b7be2974fcbb483adce27998cc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/590905 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(datetime.timedelta(days=60), datetime.timedelta(days=90)) (0.1, 0.15) 3826\n"
     ]
    }
   ],
   "source": [
    "matched_ids = []\n",
    "matched_bks = []\n",
    "for i in tqdm(range(len(day_thresh)-1)):\n",
    "    for j in tqdm(range(len(price_thresh)-1),leave=True):\n",
    "        day_range = (day_thresh[i], day_thresh[i+1])\n",
    "        price_range = (price_thresh[j], price_thresh[j+1])\n",
    "        try:\n",
    "            if retdict1[(day_range, price_range)]:\n",
    "                pass\n",
    "        except:\n",
    "            fourth_match = threshold_match(crmls_closings[~crmls_closings['id'].isin(matched_ids)], bk_deeds[~bk_deeds.bk_id.isin(matched_bks)], day_range, price_range)\n",
    "            fourth_match['match_type'] = ['4_threshold']*len(fourth_match)\n",
    "            retdict1[(day_range, price_range)] = fourth_match\n",
    "            matched_ids += list(fourth_match['id'])\n",
    "            matched_bks += list(fourth_match['bk_id'])\n",
    "            with open('data/threshold_matching.pkl', 'wb') as f:\n",
    "                pkl.dump(retdict1, f)\n",
    "            print(day_range, price_range, fourth_match['id'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14021811\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dpid</th>\n",
       "      <th>recordingdate</th>\n",
       "      <th>salesprice</th>\n",
       "      <th>standardizedlanduse</th>\n",
       "      <th>propertyfullstreetaddress</th>\n",
       "      <th>propertycityname</th>\n",
       "      <th>propertyzipcode</th>\n",
       "      <th>propertyhousenumber</th>\n",
       "      <th>propertyunitnumber</th>\n",
       "      <th>bk_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60010012587</td>\n",
       "      <td>2015-11-04</td>\n",
       "      <td>90000.0</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>229 BRUSH ST</td>\n",
       "      <td>OAKLAND</td>\n",
       "      <td>94607.0</td>\n",
       "      <td>229</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6001001258720151104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60010012587</td>\n",
       "      <td>2016-06-01</td>\n",
       "      <td>205000.0</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>229 BRUSH ST</td>\n",
       "      <td>OAKLAND</td>\n",
       "      <td>94607.0</td>\n",
       "      <td>229</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6001001258720160601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60010012588</td>\n",
       "      <td>2016-06-01</td>\n",
       "      <td>205000.0</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>BRUSH ST</td>\n",
       "      <td>OAKLAND</td>\n",
       "      <td>94607.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6001001258820160601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60010012588</td>\n",
       "      <td>2015-11-04</td>\n",
       "      <td>90000.0</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>BRUSH ST</td>\n",
       "      <td>OAKLAND</td>\n",
       "      <td>94607.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6001001258820151104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60010012590</td>\n",
       "      <td>2004-05-25</td>\n",
       "      <td>410000.0</td>\n",
       "      <td>3010.0</td>\n",
       "      <td>311 OAK ST</td>\n",
       "      <td>OAKLAND</td>\n",
       "      <td>94607.0</td>\n",
       "      <td>311</td>\n",
       "      <td>C1</td>\n",
       "      <td>6001001259020040525</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          dpid recordingdate  salesprice  standardizedlanduse  \\\n",
       "0  60010012587    2015-11-04     90000.0               2012.0   \n",
       "1  60010012587    2016-06-01    205000.0               2012.0   \n",
       "2  60010012588    2016-06-01    205000.0               2012.0   \n",
       "3  60010012588    2015-11-04     90000.0               2012.0   \n",
       "4  60010012590    2004-05-25    410000.0               3010.0   \n",
       "\n",
       "  propertyfullstreetaddress propertycityname  propertyzipcode  \\\n",
       "0              229 BRUSH ST          OAKLAND          94607.0   \n",
       "1              229 BRUSH ST          OAKLAND          94607.0   \n",
       "2                  BRUSH ST          OAKLAND          94607.0   \n",
       "3                  BRUSH ST          OAKLAND          94607.0   \n",
       "4                311 OAK ST          OAKLAND          94607.0   \n",
       "\n",
       "  propertyhousenumber propertyunitnumber                bk_id  \n",
       "0                 229                NaN  6001001258720151104  \n",
       "1                 229                NaN  6001001258720160601  \n",
       "2                 NaN                NaN  6001001258820160601  \n",
       "3                 NaN                NaN  6001001258820151104  \n",
       "4                 311                 C1  6001001259020040525  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bk_deeds = pd.concat([pd.read_csv('data/bk_raw_deeds0.csv'), pd.read_csv('data/bk_raw_deeds1.csv'), pd.read_csv('data/bk_raw_deeds2.csv')])\n",
    "print(len(bk_deeds))\n",
    "bk_deeds['bk_id'] = bk_deeds['dpid'].astype(str) + bk_deeds['recordingdate'].astype(str)\n",
    "bk_deeds['recordingdate'] = pd.to_datetime(bk_deeds['recordingdate'], format='%Y%m%d', errors='coerce')\n",
    "bk_deeds.dropna(subset='recordingdate', inplace=True)\n",
    "bk_deeds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6543940\n"
     ]
    }
   ],
   "source": [
    "crmls_closings = pd.concat([pd.read_csv('data/crmls_all_closings0.csv'), pd.read_csv('data/crmls_all_closings1.csv'), \n",
    "                            pd.read_csv('data/crmls_all_closings2.csv'), pd.read_csv('data/crmls_all_closings3.csv'), \n",
    "                            pd.read_csv('data/crmls_all_closings4.csv'), pd.read_csv('data/crmls_all_closings5.csv')])\n",
    "print(len(crmls_closings))\n",
    "crmls_closings['sale_date'] = pd.to_datetime(crmls_closings['sale_date'], errors='coerce')\n",
    "#crmls_closings.dropna(subset='sale_date',inplace=True)\n",
    "#crmls_closings['sale_date'] = pd.to_datetime(crmls_closings['sale_date'])\n",
    "#crmls_closings['sale_date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crmls_closings = crmls_closings.merge(lh, how='left', left_on='id', right_on='listing_id')\n",
    "crmls_closings['address_check'] = crmls_closings['display_address'].combine_first(crmls_closings['address'])\n",
    "crmls_closings['zip_check'] = crmls_closings['zip'].combine_first(crmls_closings['zip-2'])\n",
    "crmls_closings['sale_date'] = crmls_closings['update_transaction'].combine_first(crmls_closings['sale_date'])\n",
    "crmls_closings['sale_price'] = crmls_closings['price'].combine_first(crmls_closings['sale_price'])\n",
    "crmls_closings = crmls_closings[['id', 'rebny_id', 'building_id', 'sale_date', 'sale_price', 'address_check', 'zip_check']]\n",
    "crmls_closings.columns = ['id', 'rebny_id', 'building_id', 'listings_sale_date', 'listings_sale_price', 'address', 'zip']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "050ebdd0466f47c7b34113ae276a4e86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/35 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "587e4715eb67483ea632f4285a59f7d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "output = {}\n",
    "for k in tqdm(retdict, total=len(retdict.keys())):\n",
    "    bucket = retdict[k].merge(bk_deeds, on='bk_id', how='inner').merge(crmls_closings, on='id', how='inner')[['id', 'bk_id', 'match_type', 'propertyfullstreetaddress', 'propertyunitnumber', 'propertyzipcode', 'salesprice', 'recordingdate', 'building_id', 'address', 'zip', 'listings_sale_price', 'listings_sale_date']]\n",
    "    try:\n",
    "        bucket = bucket.sample(10000, random_state=42)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        try:\n",
    "            output[f'{k[0][0].days}-{k[0][1].days} days,{k[1][0]*100:.0f}%-{k[1][1]*100:.0f}% price'] = bucket\n",
    "        except:\n",
    "            output[f'{k[0][0].days}-{k[0][1].days} days,>{k[1][0]*100:.0f}% price'] = bucket\n",
    "    except:\n",
    "        try:\n",
    "            output[f'>{k[0][0].days} days,{k[1][0]*100:.0f}%-{k[1][1]*100:.0f}% price'] = bucket\n",
    "        except:\n",
    "            output[f'>{k[0][0].days} days,>{k[1][0]*100:.0f}% price'] = bucket\n",
    "\n",
    "output1 = {}\n",
    "for k in tqdm(retdict1, total=len(retdict1.keys())):\n",
    "    bucket = retdict1[k].merge(bk_deeds, on='bk_id', how='inner').merge(crmls_closings, on='id', how='inner')[['id', 'bk_id', 'match_type', 'propertyfullstreetaddress', 'propertyunitnumber', 'propertyzipcode', 'salesprice', 'recordingdate', 'building_id', 'address', 'zip', 'listings_sale_price', 'listings_sale_date']]\n",
    "    try:\n",
    "        bucket = bucket.sample(10000, random_state=42)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        try:\n",
    "            output1[f'TM_{k[0][0].days}-{k[0][1].days} days,{k[1][0]*100:.0f}%-{k[1][1]*100:.0f}% price'] = bucket\n",
    "        except:\n",
    "            output1[f'TM_{k[0][0].days}-{k[0][1].days} days,>{k[1][0]*100:.0f}% price'] = bucket\n",
    "    except:\n",
    "        try:\n",
    "            output1[f'TM_>{k[0][0].days} days,{k[1][0]*100:.0f}%-{k[1][1]*100:.0f}% price'] = bucket\n",
    "        except:\n",
    "            output1[f'TM_>{k[0][0].days} days,>{k[1][0]*100:.0f}% price'] = bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report_writer(dfs:dict, report_name:str):\n",
    "    \"\"\"Creates an excel report using a dictionary of dfs.\n",
    "\n",
    "    Args:\n",
    "        dfs (dict): Data\n",
    "        report_name (str): Name of file.\n",
    "    \"\"\"\n",
    "    writer = pd.ExcelWriter(report_name, engine='xlsxwriter')\n",
    "    workbook = writer.book\n",
    "    format = workbook.add_format()\n",
    "    format.set_align('center')\n",
    "    for sheetname, df in dfs.items():\n",
    "        df.to_excel(writer, sheet_name=sheetname, index=False)\n",
    "        worksheet = writer.sheets[sheetname]\n",
    "        for idx, col in enumerate(df):\n",
    "            series =df[col]\n",
    "            max_len = max((\n",
    "                series.astype(str).map(len).max(),\n",
    "                len(str(series.name))\n",
    "            ))+1\n",
    "            worksheet.set_column(idx, idx, max_len, format)\n",
    "\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(output.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_writer(output, 'data/output/matches_by_bucket.xlsx')\n",
    "report_writer(output1, 'data/output/threshold_matches_by_bucket.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bk_deeds[bk_deeds['bk_id'].isin(retdict[(timedelta(0), timedelta(days=14)), (0, 0.1)]['bk_id'])].to_csv('data/output/deeds_to_hide_0_14.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bk_deeds[bk_deeds['bk_id'].isin(retdict[(timedelta(14), timedelta(days=30)), (0, 0.1)]['bk_id'])].to_csv('data/output/deeds_to_hide_14_30.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bk_deeds[bk_deeds['bk_id'].isin(retdict[(timedelta(30), timedelta(days=90)), (0, 0.1)]['bk_id'])].to_csv('data/output/deeds_to_hide_30_90.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pw",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
